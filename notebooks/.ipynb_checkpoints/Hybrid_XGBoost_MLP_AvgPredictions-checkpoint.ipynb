{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58bd26b-ca64-43fa-89d9-0afb9bf6651c",
   "metadata": {},
   "source": [
    "**This hybrid approach will average predictions from two models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d94d959-bacd-49e7-877e-2fcc87b98ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4b580d-3d04-4b87-834d-f25841fa1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess dataset\n",
    "data_filepath = '../data/processed/cleaned_diabetes_one_hot_encoding.csv'\n",
    "df = pd.read_csv(data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d94d87-05ea-45ec-9bde-eaf20e0e6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('diabetes', axis=1)\n",
    "y = df['diabetes']\n",
    "\n",
    "# Address class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02829f70-ce48-470c-8d52-274baf7a018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87e77342-a276-4d08-8ada-b300dfa80b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features for MLP\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c41b3bb0-2976-47e3-ab76-41e3442625c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model Training\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.8647783037718892,\n",
    "    learning_rate=0.04840129264965742,\n",
    "    max_depth=4,  # Adjusted from original 'max_depth': 1, adding 3 as per adjustment logic\n",
    "    min_child_weight=1.0,\n",
    "    n_estimators=329,\n",
    "    subsample=0.9160065601766973,\n",
    "    objective='binary:logistic',\n",
    "    seed=42\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b3c882-4aa4-4ea8-a7a9-9244c184616f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033/1033 [==============================] - 1s 695us/step\n"
     ]
    }
   ],
   "source": [
    "# MLP Model Training\n",
    "mlp_model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "mlp_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "mlp_model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2, batch_size=64, verbose=0)\n",
    "y_pred_mlp = mlp_model.predict(X_test_scaled).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d5f6a66-6e5b-4e18-ab43-bc98ba9f59fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 0.9733369650747533\n",
      "Combined Model ROC AUC: 0.9969812659083899\n",
      "Combined Model Confusion Matrix:\n",
      " [[16175   223]\n",
      " [  658 15986]]\n",
      "Combined Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     16398\n",
      "           1       0.99      0.96      0.97     16644\n",
      "\n",
      "    accuracy                           0.97     33042\n",
      "   macro avg       0.97      0.97      0.97     33042\n",
      "weighted avg       0.97      0.97      0.97     33042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions by averaging the probability scores\n",
    "combined_pred_prob = (y_pred_xgb + y_pred_mlp) / 2\n",
    "combined_pred_final = np.where(combined_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "# Evaluation\n",
    "accuracy_combined = accuracy_score(y_test, combined_pred_final)\n",
    "roc_auc_combined = roc_auc_score(y_test, combined_pred_prob)\n",
    "conf_matrix_combined = confusion_matrix(y_test, combined_pred_final)\n",
    "class_report_combined = classification_report(y_test, combined_pred_final)\n",
    "\n",
    "# Displaying the combined model results\n",
    "print(f\"Combined Model Accuracy: {accuracy_combined}\")\n",
    "print(f\"Combined Model ROC AUC: {roc_auc_combined}\")\n",
    "print(\"Combined Model Confusion Matrix:\\n\", conf_matrix_combined)\n",
    "print(\"Combined Model Classification Report:\\n\", class_report_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "790f3722-8a1d-4571-8db9-a3180a3a93e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResults from previous run:\\nCombined Model Accuracy: 0.9733369650747533\\nCombined Model ROC AUC: 0.9969812659083899\\nCombined Model Confusion Matrix:\\n [[16175   223]\\n [  658 15986]]\\nCombined Model Classification Report:\\n               precision    recall  f1-score   support\\n\\n           0       0.96      0.99      0.97     16398\\n           1       0.99      0.96      0.97     16644\\n\\n    accuracy                           0.97     33042\\n   macro avg       0.97      0.97      0.97     33042\\nweighted avg       0.97      0.97      0.97     33042\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Results from previous run:\n",
    "Combined Model Accuracy: 0.9733369650747533\n",
    "Combined Model ROC AUC: 0.9969812659083899\n",
    "Combined Model Confusion Matrix:\n",
    " [[16175   223]\n",
    " [  658 15986]]\n",
    "Combined Model Classification Report:\n",
    "               precision    recall  f1-score   support\n",
    "\n",
    "           0       0.96      0.99      0.97     16398\n",
    "           1       0.99      0.96      0.97     16644\n",
    "\n",
    "    accuracy                           0.97     33042\n",
    "   macro avg       0.97      0.97      0.97     33042\n",
    "weighted avg       0.97      0.97      0.97     33042\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61609865-eb4b-432f-8566-f30bea5bdfe3",
   "metadata": {},
   "source": [
    "**Stacking Hybrid Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af7b59a7-368a-4b6e-bf6f-f7b373edacb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4131/4131 [==============================] - 3s 657us/step\n",
      "Stacking Ensemble Model Accuracy: 0.9763028872344289\n",
      "Stacking Ensemble Model ROC AUC: 0.9974446458306605\n",
      "Stacking Ensemble Model Confusion Matrix:\n",
      " [[16131   267]\n",
      " [  516 16128]]\n",
      "Stacking Ensemble Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     16398\n",
      "           1       0.98      0.97      0.98     16644\n",
      "\n",
      "    accuracy                           0.98     33042\n",
      "   macro avg       0.98      0.98      0.98     33042\n",
      "weighted avg       0.98      0.98      0.98     33042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Generate predictions on the training set for stacking\n",
    "y_pred_xgb_train = xgb_model.predict_proba(X_train)[:, 1]\n",
    "y_pred_mlp_train = mlp_model.predict(X_train_scaled).ravel()\n",
    "\n",
    "# Stack predictions to create a new training dataset for the meta-model\n",
    "stacked_predictions_train = np.column_stack((y_pred_xgb_train, y_pred_mlp_train))\n",
    "\n",
    "# Train the meta-model (Logistic Regression) on the stacked predictions\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(stacked_predictions_train, y_train)\n",
    "\n",
    "# Generate stacked predictions on the test set\n",
    "stacked_predictions_test = np.column_stack((y_pred_xgb, y_pred_mlp))\n",
    "\n",
    "# Use the meta-model to make the final prediction\n",
    "final_pred_prob = meta_model.predict_proba(stacked_predictions_test)[:, 1]\n",
    "final_pred = np.where(final_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "# Evaluate the stacking ensemble model\n",
    "accuracy_stacking = accuracy_score(y_test, final_pred)\n",
    "roc_auc_stacking = roc_auc_score(y_test, final_pred_prob)\n",
    "conf_matrix_stacking = confusion_matrix(y_test, final_pred)\n",
    "class_report_stacking = classification_report(y_test, final_pred)\n",
    "\n",
    "# Display the stacking ensemble model results\n",
    "print(f\"Stacking Ensemble Model Accuracy: {accuracy_stacking}\")\n",
    "print(f\"Stacking Ensemble Model ROC AUC: {roc_auc_stacking}\")\n",
    "print(\"Stacking Ensemble Model Confusion Matrix:\\n\", conf_matrix_stacking)\n",
    "print(\"Stacking Ensemble Model Classification Report:\\n\", class_report_stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff8163b-11ea-4234-a692-b0d2a32ab7ed",
   "metadata": {},
   "source": [
    "**Weighted Averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "884ab7dc-e7a8-4006-8d85-8674fa3223c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Averaging Hybrid Model Accuracy: 0.9673445917317354\n",
      "Weighted Averaging Hybrid Model ROC AUC: 0.9962761631706424\n",
      "Weighted Averaging Hybrid Model Confusion Matrix:\n",
      " [[16093   305]\n",
      " [  774 15870]]\n",
      "Weighted Averaging Hybrid Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     16398\n",
      "           1       0.98      0.95      0.97     16644\n",
      "\n",
      "    accuracy                           0.97     33042\n",
      "   macro avg       0.97      0.97      0.97     33042\n",
      "weighted avg       0.97      0.97      0.97     33042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign weights to predictions (assuming MLP is more reliable)\n",
    "weight_xgb = 1\n",
    "weight_mlp = 2  # Giving more weight to the MLP model's predictions\n",
    "\n",
    "# Calculate weighted average of probability scores\n",
    "weighted_avg_pred_prob = (y_pred_xgb * weight_xgb + y_pred_mlp * weight_mlp) / (weight_xgb + weight_mlp)\n",
    "weighted_avg_pred_final = np.where(weighted_avg_pred_prob > 0.5, 1, 0)\n",
    "\n",
    "# Evaluate the weighted averaging hybrid model\n",
    "accuracy_weighted_avg = accuracy_score(y_test, weighted_avg_pred_final)\n",
    "roc_auc_weighted_avg = roc_auc_score(y_test, weighted_avg_pred_prob)\n",
    "conf_matrix_weighted_avg = confusion_matrix(y_test, weighted_avg_pred_final)\n",
    "class_report_weighted_avg = classification_report(y_test, weighted_avg_pred_final)\n",
    "\n",
    "# Display the weighted averaging hybrid model results\n",
    "print(f\"Weighted Averaging Hybrid Model Accuracy: {accuracy_weighted_avg}\")\n",
    "print(f\"Weighted Averaging Hybrid Model ROC AUC: {roc_auc_weighted_avg}\")\n",
    "print(\"Weighted Averaging Hybrid Model Confusion Matrix:\\n\", conf_matrix_weighted_avg)\n",
    "print(\"Weighted Averaging Hybrid Model Classification Report:\\n\", class_report_weighted_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35740d73-62cb-4eee-b33c-685b5d671559",
   "metadata": {},
   "source": [
    "**Feature Level Fusion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33603837-5906-4dbb-9a77-02c2c0507b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1033/1033 [==============================] - 1s 684us/step\n",
      "Feature-Level Fusion Model Accuracy: 0.979450396465105\n",
      "Feature-Level Fusion Model ROC AUC: 0.9975672586140495\n",
      "Feature-Level Fusion Model Confusion Matrix:\n",
      " [[16350    48]\n",
      " [  631 16013]]\n",
      "Feature-Level Fusion Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     16398\n",
      "           1       1.00      0.96      0.98     16644\n",
      "\n",
      "    accuracy                           0.98     33042\n",
      "   macro avg       0.98      0.98      0.98     33042\n",
      "weighted avg       0.98      0.98      0.98     33042\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate XGBoost predictions on the training data for fusion\n",
    "y_pred_xgb_train = xgb_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Scale XGBoost predictions (feature scaling is important for neural networks)\n",
    "scaler_xgb_pred = StandardScaler()\n",
    "y_pred_xgb_train_scaled = scaler_xgb_pred.fit_transform(y_pred_xgb_train.reshape(-1, 1))\n",
    "\n",
    "# Combine XGBoost predictions with original scaled features for the MLP training set\n",
    "X_train_scaled_with_xgb = np.hstack((X_train_scaled, y_pred_xgb_train_scaled))\n",
    "\n",
    "# Adjust the MLP model to accommodate the additional XGBoost prediction feature\n",
    "mlp_model_with_xgb = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled_with_xgb.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "mlp_model_with_xgb.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the MLP model with the combined dataset\n",
    "mlp_model_with_xgb.fit(X_train_scaled_with_xgb, y_train, epochs=100, validation_split=0.2, batch_size=64, verbose=0)\n",
    "\n",
    "# Prepare the test data: Generate XGBoost predictions and combine with scaled features\n",
    "y_pred_xgb_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_xgb_test_scaled = scaler_xgb_pred.transform(y_pred_xgb_test.reshape(-1, 1))\n",
    "X_test_scaled_with_xgb = np.hstack((X_test_scaled, y_pred_xgb_test_scaled))\n",
    "\n",
    "# Predict with the MLP model using the combined test data\n",
    "y_pred_mlp_with_xgb = mlp_model_with_xgb.predict(X_test_scaled_with_xgb).ravel()\n",
    "\n",
    "# Final evaluation\n",
    "final_pred_with_xgb = np.where(y_pred_mlp_with_xgb > 0.5, 1, 0)\n",
    "accuracy_with_xgb = accuracy_score(y_test, final_pred_with_xgb)\n",
    "roc_auc_with_xgb = roc_auc_score(y_test, y_pred_mlp_with_xgb)\n",
    "conf_matrix_with_xgb = confusion_matrix(y_test, final_pred_with_xgb)\n",
    "class_report_with_xgb = classification_report(y_test, final_pred_with_xgb)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Feature-Level Fusion Model Accuracy: {accuracy_with_xgb}\")\n",
    "print(f\"Feature-Level Fusion Model ROC AUC: {roc_auc_with_xgb}\")\n",
    "print(\"Feature-Level Fusion Model Confusion Matrix:\\n\", conf_matrix_with_xgb)\n",
    "print(\"Feature-Level Fusion Model Classification Report:\\n\", class_report_with_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6ef0b6-2bf3-4996-90f7-e4809fff71e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
